{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training the SKLearn model"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["When this notebook is executed, we expect <br>**(1)** Serialized train and test data tracked with DVC <br>**(2)** Knowledge of their location within DVCFileSystem (Path within Git Repository for DVC tracking)\n","\n","Steps covered in this notebook:\n","1. Retrieve parameters\n","2. Download training package\n","3. Initialize and train ```XGBoost``` (Regressor) model\n","4. Download test package\n","5. Run initial testing and check metrics\n","6. Serialize and track model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Install required packages.\n","# TODO: Create IBM Cloud Software Configuration for those\n","!pip install ibm-cos-sdk xgboost ibm_watson_studio_pipelines 'dvc[s3]' # dvc[all] alternatively, however, COS is covered by S3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ibm_watson_studio_pipelines import WSPipelines\n","from ibm_watson_machine_learning import APIClient\n","import ibm_boto3\n","\n","from botocore.client import Config\n","from sklearn.model_selection import train_test_split\n","from dataclasses import dataclass\n","import numpy as np\n","import pandas as pd\n","\n","import pickle\n","import dvc.api\n","import io\n","\n","import logging\n","import os, types\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 1. Retrieve Parameters\n","**Note**: If you are running this notebook outside of a Watson Studio Pipeline execution. Make sure to set the environment variables that the Pipeline environment would have passed to the notebook.\n","Refer to ```credentials.py```."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment this cell and put your credentials in credentials.py to run locally.\n","from credentials2 import set_env_variables_for_credentials\n","set_env_variables_for_credentials()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CLOUD_API_KEY = os.getenv(\"CLOUD_API_KEY\")\n","GIT_REPOSITORY = os.getenv(\"GIT_REPOSITORY\")\n","train_package_dvc_location = os.getenv(\"train_package_dvc_location\") \n","test_package_dvc_location = os.getenv(\"test_package_dvc_location\")\n","\n","# Name of serialized model is passed as pipeline param\n","MODEL_FILENAME = os.getenv(\"MODEL_FILENAME\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 2. Pre-Training: DVC Pull and Deserialize Training Data Package"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO: Make pipeline param\n","repo = \\\n","    GIT_REPOSITORY"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrieve dataset from tracking information in git. The repository itself contains the remote storage info and credentials.\n","train_package = pickle.load(io.BytesIO(dvc.api.read(train_package_dvc_location,repo=repo, mode=\"rb\")))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train = train_package['X_train']\n","y_train = train_package['y_train'] "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 3. Initialize and train ```XGBoost``` (Regressor) model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import xgboost as xgb\n","\n","# Define the hyperparameters for XGBRegressor\n","params = {\n","    'objective': 'reg:squarederror',  # Objective function for regression\n","    'learning_rate': 0.001,             # Learning rate\n","    'max_depth': 4,                   # Maximum depth of each tree\n","    'n_estimators': 500,              # Number of trees (boosting rounds)\n","    'subsample': 0.6,                 # Subsample ratio of the training instances\n","    'colsample_bytree': 0.6,          # Subsample ratio of columns when constructing each tree\n","    'gamma': 0.1,                     # Minimum loss reduction required to make a further partition on a leaf node\n","    'reg_alpha': 0.25,                 # L1 regularization term on weights\n","    'reg_lambda': 0.25,                # L2 regularization term on weights\n","    'random_state': 42                # Random seed for reproducibility\n","}\n","\n","# Create an instance of XGBRegressor\n","model = xgb.XGBRegressor(**params)\n","\n","X_train = X_train.apply(pd.to_numeric, errors=\"coerce\")\n","\n","model.fit(X_train.to_numpy(), y_train.to_numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.score(X_train.tail(2000000).to_numpy(), y_train.tail(2000000).to_numpy())"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 4. Download test package"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrieve test package for brief testing\n","test_package = pickle.load(io.BytesIO(dvc.api.read(test_package_dvc_location,repo=repo, mode=\"rb\")))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make predictions on the testing data\n","X_test = test_package['X_test']\n","y_test = test_package['y_test']"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 5. Run initial testing and check metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# NOTE: Step no longer necessary\n","# # Drop columns that were dropped in X_train earlier\n","# X_test = X_test.drop(dropped_cols, axis=1)\n","\n","# Convert to ensure numeric data (avoid e.g. Timestamp() data type)\n","X_test = X_test.apply(pd.to_numeric, errors=\"coerce\")\n","\n","y_pred = model.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# In-line comparison of actual prediction versus known predictant \n","validation_df = pd.DataFrame({'y_pred': y_pred, 'y_validate': y_test})\n","validation_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Misc testing\n","# See how many predictions are off by no more than 1-25% \n","# Filter the DataFrame based on the condition\n","filtered_df = validation_df[abs(validation_df['y_pred'] - validation_df['y_validate']) <= 0.25 * validation_df['y_pred']]\n","filtered_df2 = filtered_df[abs(validation_df['y_pred'] - validation_df['y_validate']) > 0.01 * validation_df['y_pred']]\n","\n","# Print the filtered DataFrame\n","filtered_df2\n","# Percent of predictions which were within a +-25% range of the actual value\n","((100/len(validation_df) * len(filtered_df2)))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Check a few metrics\n","\n","You may want to set a threshold for some metrics in the Watson Studio Pipeline. If so, make sure to pass the value (you want to set a threshold for) with the training_params down below."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# Calculate the mean squared error (MSE)\n","mse = mean_squared_error(y_test, y_pred)\n","print('Mean Squared Error (MSE):', mse)\n","\n","# Calculate the mean absolute error (MAE)\n","mae = mean_absolute_error(y_test, y_pred)\n","print('Mean Absolute Error (MAE):', mae)\n","\n","# Calculate the R-squared score (coefficient of determination)\n","r2 = r2_score(y_test, y_pred)\n","\n","# Print the R-squared score\n","print('R-squared Score:', r2)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 6. Serialize and track model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(MODEL_FILENAME, 'wb') as f:\n","    pickle.dump(model, f)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["##### Track Model with DVC"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!echo $MODEL_FILENAME"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!git clone $GIT_REPOSITORY"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && mkdir model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mv $MODEL_FILENAME dvc-testing/model/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && dvc add model/$MODEL_FILENAME"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && git add model/$MODEL_FILENAME.dvc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && git commit -m \"New regression model\" && git push"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && dvc push"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_params = {}\n","training_params['training_completed'] = True\n","training_params['model_filename'] = MODEL_FILENAME"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipelines_client = WSPipelines.from_apikey(apikey=CLOUD_API_KEY)\n","pipelines_client.store_results(training_params)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":1}
