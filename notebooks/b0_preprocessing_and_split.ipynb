{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Pull Newest Full Data, make Train Test split and Track those."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["When this notebook is executed, we expect <br>**(1)** dataset to split <br>**(2)** the dataset to be tracked (since we are retrieving it via DVC)\n","\n","Steps covered in this notebook:\n","1. Retrieve parameters\n","2. Download dataset via DVC and deserialize\n","3. Initial data preprocessing (e.g. drop single value columns)\n","4. Make Test-Train-Split\n","5. Serialize split data as train and test package (train_package = X_train, y_train and *vice versa*)\n","6. Set-up DVC\n","7. Track train and test package\n","8. Check whether both data packages are tracked via ```DVCFileSystem```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Install required packages.\n","# TODO: Create IBM Cloud Software Configuration for those\n","!pip install ibm-cos-sdk ibm_watson_studio_pipelines 'dvc[all]' # dvc[all] alternatively, however, COS is covered by S3"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ibm_watson_studio_pipelines import WSPipelines\n","import ibm_boto3\n","\n","from botocore.client import Config\n","from sklearn.model_selection import train_test_split\n","from dataclasses import dataclass\n","import numpy as np\n","import pandas as pd\n","\n","import pickle\n","import dvc.api\n","import io\n","\n","import logging\n","import os, types\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Retrieve parameters\n","\n","**Note**: If you are running this notebook outside of a Watson Studio Pipeline execution. Make sure to set the environment variables that the Pipeline environment would have passed to the notebook.\n","Refer to ```credentials.py```."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment this cell and put your credentials in credentials.py to run locally.\n","# from credentials2 import set_env_variables_for_credentials\n","# set_env_variables_for_credentials()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CLOUD_API_KEY = os.getenv(\"CLOUD_API_KEY\")\n","DATA_FILENAME = os.getenv(\"serialized_data_filename\")\n","GIT_REPOSITORY = os.getenv(\"GIT_REPOSITORY\")\n","REPO_NAME = os.getenv(\"REPO_NAME\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["REPO_NAME = \"dvc-testing\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### DVC Pull and Deserialize Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO: Make pipeline param\n","repo = \\\n","    GIT_REPOSITORY"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Retrieve dataset from tracking information in git. The repository itself contains the remote storage info and credentials.\n","data = pickle.load(io.BytesIO(dvc.api.read(f\"data/{DATA_FILENAME}\",repo=repo, mode=\"rb\")))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Drop rows where at least one col-value is NaN\n","print(f\"Dropped {len(data)-len(data.dropna(axis=0))} rows.\")\n","data = data.dropna(axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# E.g. col 'step' has only a single unique value. Its existence has no effect on training is solely a waste of resources.\n","# Therefore we will drop all cols with that characteristic\n","for key in data.keys():\n","    if len(data[key].unique()) < 2:\n","        print(f\"col '{key}' dropped because it bears no more than one unique value.\")\n","        data = data.drop(key, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert non-numeric columns to numeric values\n","data['time'] = pd.to_datetime(data['time'])  # Convert dates to datetime objects\n","\n","#data['latitude'] = data['latitude'].astype('category').cat.codes  # Encode coordinates as categorical codes\n","#data['longitude'] = data['longitude'].astype('category').cat.codes  # Encode coordinates as categorical codes"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Test Train Split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Assuming your large table is stored in a pandas DataFrame called 'df'\n","X = data.drop('dis24', axis=1)  # Extract input features by dropping the target column\n","y = data['dis24']  # Extract the target column\n","\n","\n","# Perform train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def serialize(obj, target_path):\n","    try:\n","        with open(target_path, 'wb') as _file:\n","            pickle.dump(obj, _file)\n","    except Exception as e:\n","        print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_target = \"/data/train_package.pkl\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_package = {}\n","train_package[\"X_train\"] = X_train\n","train_package[\"y_train\"] = y_train\n","\n","serialize(train_package, f\"{REPO_NAME}{train_target}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_target = \"/data/test_package.pkl\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_package = {}\n","test_package[\"X_test\"] = X_test\n","test_package[\"y_test\"] = y_test\n","\n","serialize(test_package, f\"{REPO_NAME}{test_target}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["###  Setup DVC Situation\n","\n","Since we assume CPDaaS as environment, we will need to clone the dvc setup repository again.\n","Run the line shown below.\n","\n","```\n","!git clone https://[GIT_TOKEN]@github.com/[GIT_REPOSITORY].git\n","````\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# @hidden_cell\n","!git clone $GIT_REPOSITORY"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && dvc add data/train_package.pkl data/test_package.pkl"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && git add data/.gitignore data/train_package.pkl.dvc data/test_package.pkl.dvc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && git config --global user.email \"ilias.ennmouri@ibm.com\"\n","!cd dvc-testing && git config --global user.name \"Ilias Ennmouri\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && git commit -m \"New train test subsets\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cd dvc-testing && dvc push && git push"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from dvc.api import DVCFileSystem"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fs = DVCFileSystem(GIT_REPOSITORY, rev=\"main\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dvc_tracked = fs.find(\"/\", detail=False, dvc_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["training_tracked = True if train_target in dvc_tracked else False\n","training_tracked"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_tracked = True if test_target in dvc_tracked else False\n","test_tracked"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_params = {}\n","validation_params['training_package_tracked'] = training_tracked\n","validation_params['test_package_tracked'] = test_tracked\n","validation_params['train_package_dvc_location'] = train_target\n","validation_params['test_package_dvc_location'] = test_target"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipelines_client = WSPipelines.from_apikey(apikey=CLOUD_API_KEY)\n","pipelines_client.store_results(validation_params)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":1}
